# Note: You only need to set the variables you normally would with '-e' flags.
# You do not need to set them all if they will go unused.

# vLLM Inference
VLLM_URL=
VLLM_API_KEY=
# Optional Variables
VLLM_MAX_TOKENS=
VLLM_TLS_VERIFY=

# Ollama Inference
OLLAMA_URL=

# OpenAI Inference
OPENAI_API_KEY=

# Question Validation Safety Shield
PROVIDER=
MODEL_NAME=

# Other
LLAMA_STACK_LOGGING=